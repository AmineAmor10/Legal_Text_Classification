{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import fasttext.util\n",
    "import time\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "# fasttext.util.download_model('fr', if_exists='ignore')  # French\n",
    "ft = fasttext.load_model('cc.fr.300.bin')\n",
    "print(\"OK\")\n",
    "\n",
    "print(\"Time taken: \", (time.process_time() - start), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.875173807144165, 'bonsoir'),\n",
       " (0.809287428855896, 'bonjours'),\n",
       " (0.7799237966537476, 'Bonjour'),\n",
       " (0.760585606098175, 'boujour'),\n",
       " (0.748824417591095, 'Bonsoir'),\n",
       " (0.748317301273346, 'rebonjour'),\n",
       " (0.7253685593605042, 'bonjour.'),\n",
       " (0.7218137383460999, 're-bonjour'),\n",
       " (0.7111150622367859, '-bonjour'),\n",
       " (0.706505537033081, 'bjr')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "print(ft.get_word_vector('bonjour').shape)\n",
    "ft.get_nearest_neighbors('bonjour')\n",
    "\n",
    "print(\"Time taken: \", (time.process_time() - start), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,)\n"
     ]
    }
   ],
   "source": [
    "print(ft.get_word_vector('bonjour').shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-01-27 17:46:33--  http://nlp.stanford.edu/data/glove.6B.zip\n",
      "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
      "--2021-01-27 17:46:34--  https://nlp.stanford.edu/data/glove.6B.zip\n",
      "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
      "--2021-01-27 17:46:34--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
      "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
      "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 862182613 (822M) [application/zip]\n",
      "Saving to: ‘glove.6B.zip’\n",
      "\n",
      "glove.6B.zip        100%[===================>] 822.24M  1.56MB/s    in 23m 30s \n",
      "\n",
      "2021-01-27 18:10:05 (597 KB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# !wget http://nlp.stanford.edu/data/glove.6B.zip\n",
    "# !unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get into the right directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/amineamor/Desktop/Bert_Exercise\n",
      "Current working directory: /Users/amineamor/Desktop/Bert_Exercise/data\n"
     ]
    }
   ],
   "source": [
    "# Import the os module\n",
    "import os\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))\n",
    "\n",
    "# Change the current working directory\n",
    "os.chdir('data')\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory: {0}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# path_to_glove_file = os.path.join(\n",
    "#     os.path.expanduser(\"~\"), \"glove.6B.100d.txt\"\n",
    "# )\n",
    "import numpy as np\n",
    "\n",
    "embeddings_index = {}\n",
    "with open(\"glove.6B.100d.txt\") as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "file_names = ['CRIM.csv', 'SOC.csv', 'COM.csv', 'CIV.csv']\n",
    "dataframes = []\n",
    "\n",
    "\n",
    "for file in file_names: \n",
    "    df = pd.read_csv(file, header=None)\n",
    "    dataframes.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data shape:  (27998, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>&lt;p&gt;COUR D'APPEL DE ROUEN &lt;/p&gt;\\n&lt;p&gt;CHAMBRE DE L...</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>\\n&lt;br&gt;COUR D'APPEL DE MONTPELLIER &lt;br&gt;CHAMBRE ...</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>\\nDOSSIER N 08 / 00863 &lt;br&gt;ARRÊT DU 21 AVRIL 2...</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\\nCOUR D'APPEL DE MONTPELLIER &lt;br&gt;CHAMBRE DE L...</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>\\n&lt;p&gt;\\n&lt;br clear=\"none\"&gt;COUR D'APPEL DE MONTPE...</td>\n",
       "      <td>CRIM</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text label\n",
       "0  <p>COUR D'APPEL DE ROUEN </p>\\n<p>CHAMBRE DE L...  CRIM\n",
       "1  \\n<br>COUR D'APPEL DE MONTPELLIER <br>CHAMBRE ...  CRIM\n",
       "2  \\nDOSSIER N 08 / 00863 <br>ARRÊT DU 21 AVRIL 2...  CRIM\n",
       "3  \\nCOUR D'APPEL DE MONTPELLIER <br>CHAMBRE DE L...  CRIM\n",
       "4  \\n<p>\\n<br clear=\"none\">COUR D'APPEL DE MONTPE...  CRIM"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat(dataframes).rename(columns={0:'text', 1:'label'})\n",
    "print(\"data shape: \", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Preprocess text data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each legal decision (row), we select the first 150 words since we believe most of the crucial information is at the beginning of the text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words_select = 150\n",
    "text_list = [\" \".join(row.split(\" \")[:num_words_select]) for row in df['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each decision text, we remove some irrelevant information such as xml tags (meta-data), punctuation, common words (e.g \"la\", \"de\", \"comme\"...) and dates. This data does not discriminate between the different types of decisions (i.e \"SOC\", \"CIV\", \"COM\" and \"CRIM\") and should therefore be ignored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/amineamor/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords # refer to common words\n",
    "import re\n",
    "\n",
    "def remove_xml_tags(text):\n",
    "    no_xml = BeautifulSoup(text, 'lxml').text\n",
    "    return no_xml\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    no_punc = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return no_punc\n",
    "\n",
    "# remove common french words\n",
    "def remove_stop_words(text): \n",
    "    no_stop_words = [w for w in text.split() if w not in stopwords.words('french')]\n",
    "    return \" \".join(no_stop_words)\n",
    "\n",
    "def remove_new_lines(text):\n",
    "    no_new_lines = text.replace(\"\\n\",\" \")\n",
    "    return no_new_lines\n",
    "\n",
    "def remove_dates(text):\n",
    "    months_regex = \"((Janvier(?i)|Février(?i)|Fevrier(?i)|Mars(?i)|Avril(?i)|Mai(?i)|Juin(?i)|Juillet(?i)|Août(?i)|Aout(?i)|Septembre(?i)|Octobre(?i)|Novembre(?i)|Décembre(?i)|Decembre(?i))?)\"\n",
    "    year_regex = \"[1-3][0-9]{3}\"\n",
    "    classic_date_format =  \"\\d\\d\\s\"+months_regex+\"\\s\"+year_regex\n",
    "    \n",
    "    text = re.sub(classic_date_format, '', text)\n",
    "    text = re.sub(months_regex, '', text)\n",
    "    no_dates = re.sub(year_regex, '', text)\n",
    "    \n",
    "    return no_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note that the punctuation will be automatically removed later, by the Tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = remove_xml_tags(text)\n",
    "    text = remove_new_lines(text)\n",
    "#     text = remove_punctuation(text) \n",
    "#     text = remove_stop_words(text)\n",
    "    output = remove_dates(text)  \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amineamor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:30: DeprecationWarning: Flags not at the start of the expression '\\\\d\\\\d\\\\s((Janvier(?i)|' (truncated)\n",
      "/Users/amineamor/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:31: DeprecationWarning: Flags not at the start of the expression '((Janvier(?i)|Févrie' (truncated)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  112.91053000000001  seconds\n"
     ]
    }
   ],
   "source": [
    "start = time.process_time()\n",
    "\n",
    "data = []\n",
    "for text in text_list:\n",
    "    new_text = preprocess(text)\n",
    "    data.append(new_text)\n",
    "    \n",
    "print(\"Time taken: \", (time.process_time() - start), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {'CRIM':0,'SOC':1,'COM':2,'CIV':3}\n",
    "\n",
    "data_labels = np.array([label_mapping[label] for label in df['label']])\n",
    "data_text = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27998,)\n",
      "(27998,)\n"
     ]
    }
   ],
   "source": [
    "print(data_labels.shape)\n",
    "print(data_text.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3)  Tokenize and Vectorize data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this section, we create a vocabulary which consists of a word-index mapping. Each word in our dataset is mapped to a unique integer.  Using this mapping, we then transform each text (list of words) into a vector representation, which is suitable to NLP models.\n",
    "\n",
    "### The word-index mapping and the text vectorization is performed by TensorFlow's Tokenizer module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = None # will automatically be set to the entire vocabulary size\n",
    "tokenizer = Tokenizer(num_words=num_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the tokenizer to the dataset\n",
    "\n",
    "#### By fitting the tokenizer to the data, we convert all the text to lowercase characters, remove punctuation and finally construct the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of unique words:  78569\n"
     ]
    }
   ],
   "source": [
    "tokenizer.fit_on_texts(data_text)\n",
    "\n",
    "num_words = len(tokenizer.word_index) + 1\n",
    "print(\"number of unique words: \", num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word-Index Mapping: \n",
      "\n",
      "de : 1\n",
      "la : 2\n",
      "du : 3\n",
      "au : 4\n",
      "cour : 5\n",
      "le : 6\n",
      "par : 7\n",
      "à : 8\n",
      "en : 9\n",
      "barreau : 10\n"
     ]
    }
   ],
   "source": [
    "print(\"Word-Index Mapping: \" + \"\\n\")\n",
    "for key in list(tokenizer.word_index.keys())[0:10]:\n",
    "    print(key, \":\", tokenizer.word_index[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list(tokenizer.word_index.items())[0:5]\n",
    "# embeddings_index.get('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 22765 words (55803 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = num_words\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),\n",
    "    trainable=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# --------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorize train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.24.0.\n"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_text, data_labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# texts_to_sequences converts text into vector representations\n",
    "x_train = tokenizer.texts_to_sequences(x_train)\n",
    "x_test = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create tokenizer inverse map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"grosses délivréesrépublique française aux parties le au nom du peuple français cour d'appel de paris pôle 4 chambre 1 arrêt du no 3 pages numéro d'inscription au répertoire général 15 06899 décision déférée à la cour ordonnance du cour d'appel de paris rg no 14 3 demandeur au déféré monsieur sylvain x y né le à brazzaville congo demeurant représenté par me daniel merchat avocat au barreau de seine saint denis toque 155 assisté sur l'audience par me joseph soudri de la scp soudri delpla avocat au barreau de pontoise toque no 19 substitué par me meryem afarkous avocat au barreau de seine saint denis toque pb155 madame sylvanie z épouse y née le à brazzaville demeurant représentée par me daniel merchat avocat au barreau de seine saint denis toque 155 assistée sur l'audience\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = tokenizer.word_index\n",
    "inverse_map = dict(zip(idx.values(), idx.keys()))\n",
    "\n",
    "def tokens_to_string(tokens):\n",
    "    # Map from tokens back to words.\n",
    "    words = [inverse_map[token] for token in tokens if token != 0]\n",
    "    \n",
    "    # Concatenate all words.\n",
    "    text = \" \".join(words)\n",
    "\n",
    "    return text\n",
    "\n",
    "tokens_to_string(x_train[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Pad and Truncate vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In order to process the batch of data, the RNN requires to have sequences of the same length.  To do so, we need to pad (add 0s) and truncate (shorten) vectors to guarantee they have the same dimensions.\n",
    "\n",
    "### If we set max_tokens (length of vectors) to the length of the largest vector, we will add too much padding and waste a lot of memory.\n",
    "\n",
    "### A good compromise is to set max_tokens to the average length + 2 standard deviations. This way, we theoretically cover 95% of the data (assuming it is normally distributed) and avoid excessive padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting max_tokens to 164 covers 96.0 % of the data\n"
     ]
    }
   ],
   "source": [
    "num_tokens = [len(tokens) for tokens in x_train + x_test]\n",
    "num_tokens = np.array(num_tokens)\n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "max_tokens = int(max_tokens)\n",
    "\n",
    "data_coverage = np.sum(num_tokens < max_tokens) / len(num_tokens)\n",
    "print(\"Setting max_tokens to\", max_tokens, \"covers\", np.round(data_coverage, decimals=2)*100, \"% of the data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22398, 164)\n",
      "(5600, 164)\n"
     ]
    }
   ],
   "source": [
    "pad = 'post' # adding zeros at the end of vectors when length < max_tokens\n",
    "\n",
    "x_train = pad_sequences(x_train, maxlen=max_tokens,\n",
    "                            padding=pad, truncating=pad)\n",
    "\n",
    "x_test = pad_sequences(x_test, maxlen=max_tokens,\n",
    "                           padding=pad, truncating=pad)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hot-encode target data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_train_enc = enc.fit_transform(np.array(y_train).reshape(-1,1)).toarray()\n",
    "y_test_enc = enc.fit_transform(np.array(y_test).reshape(-1,1)).toarray()\n",
    "\n",
    "y_test_enc[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Train a Recurrent Neural Network (GRU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22398,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_text, data_labels, test_size=0.2, random_state=42)\n",
    "print(x_train.shape)\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_train_enc = enc.fit_transform(np.array(y_train).reshape(-1,1)).toarray()\n",
    "y_test_enc = enc.fit_transform(np.array(y_test).reshape(-1,1)).toarray()\n",
    "\n",
    "y_test_enc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# emb = []\n",
    "# counter = 0\n",
    "# for sentence in x_train:\n",
    "#     counter +=1\n",
    "#     l = sentence.split(\" \")\n",
    "#     vecs = np.array([ft.get_word_vector(token) for token in l])\n",
    "#     if counter%100 == 0:\n",
    "#         print(\"counter : \", counter)\n",
    "#     emb.append(vecs)\n",
    "\n",
    "# embeddings = np.array(emb)\n",
    "# embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22398,)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of each input vector:  164\n",
      "Embedding size:  64\n",
      "Number of words in vocabulary:  78569\n",
      "Number of words in vocabulary:  78571\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Model\n",
    "embedding_size = 64\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Embedding(input_dim=num_words,\n",
    "#                     output_dim=embedding_size,\n",
    "#                     input_length=max_tokens,\n",
    "#                     name='layer_embedding'))\n",
    "\n",
    "# # model.add(GRU(units=32, return_sequences=True))\n",
    "# # model.add(GRU(units=16, return_sequences=True))\n",
    "# # model.add(GRU(units=8))\n",
    "# model.add(Conv1D(filters=32, kernel_size=3, activation='relu', padding=\"same\"))\n",
    "# model.add(GlobalAveragePooling1D())\n",
    "# model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "inputs = tf.keras.layers.Input(shape=(max_tokens,)) \n",
    "# embedding = Embedding(input_dim=num_words,\n",
    "#                     output_dim=embedding_size,\n",
    "#                     input_length=max_tokens,\n",
    "#                     name='layer_embedding')(inputs)\n",
    "embedding = embedding_layer(inputs)\n",
    "\n",
    "conv1d = tf.keras.layers.Conv1D(filters=32, kernel_size=3, activation='relu', padding=\"same\")(embedding)\n",
    "global_avg = tf.keras.layers.GlobalAveragePooling1D()(conv1d)\n",
    "outputs = Dense(4, activation='softmax')(global_avg)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=[outputs], name=\"text_classification_model\")\n",
    "\n",
    "\n",
    "print(\"Length of each input vector: \", max_tokens)\n",
    "print(\"Embedding size: \", embedding_size)\n",
    "print(\"Number of words in vocabulary: \", num_words)\n",
    "print(\"Number of words in vocabulary: \", num_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_classification_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 164)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 164, 100)          7857100   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 164, 32)           9632      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,866,864\n",
      "Trainable params: 7,866,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow.keras.layers import Conv1D\n",
    "# from tensorflow.keras.layers import GlobalAveragePooling1D\n",
    "# # The inputs are 128-length vectors with 10 timesteps, and the batch size is 4.\n",
    "# input_shape = (1, 10, 132)\n",
    "# x = tf.random.normal(input_shape)\n",
    "# y = Conv1D(\n",
    "# filters=32, kernel_size=3, activation='relu', padding=\"valid\", input_shape=(None,132,4))(x)\n",
    "# y = GlobalAveragePooling1D()(y)\n",
    "# print(y.shape)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_classification_model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 164)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 164, 100)          7857100   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 164, 32)           9632      \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_1 ( (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 132       \n",
      "=================================================================\n",
      "Total params: 7,866,864\n",
      "Trainable params: 7,866,864\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "optimizer = Adam(lr=1e-3)\n",
    "model.compile(loss='CategoricalCrossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To prevent overfitting, we use early stopping which stops the training as soon as the validation performance decreases for 2 consecutive epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 164) for input KerasTensor(type_spec=TensorSpec(shape=(None, 164), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 1).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 164) for input KerasTensor(type_spec=TensorSpec(shape=(None, 164), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 1).\n"
     ]
    },
    {
     "ename": "UnimplementedError",
     "evalue": " Cast string to float is not supported\n\t [[node text_classification_model/Cast (defined at <timed exec>:2) ]] [Op:__inference_train_function_865]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnimplementedError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 _r=1):\n\u001b[1;32m   1133\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    878\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 879\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    880\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2992\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2993\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2994\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2996\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1937\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1939\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1940\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1941\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    567\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    570\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnimplementedError\u001b[0m:  Cast string to float is not supported\n\t [[node text_classification_model/Cast (defined at <timed exec>:2) ]] [Op:__inference_train_function_865]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2, restore_best_weights=True)\n",
    "history = model.fit(x_train, y_train_enc, validation_split=0.10, epochs=20, batch_size=64, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the Training-Validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-69d726cc0ac1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Training'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Training')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### On the test set, the model achieves an accuracy of 97.3% and an F1-score of 97.4%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 [==============================] - 1s 3ms/step - loss: 0.0716 - accuracy: 0.9784\n",
      "CPU times: user 1.12 s, sys: 85.2 ms, total: 1.21 s\n",
      "Wall time: 789 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = model.evaluate(x_test, y_test_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score:  0.9797005653218821 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "preds = model.predict(x_test)\n",
    "y_pred = [np.argmax(p) for p in preds]\n",
    "\n",
    "print(\"F1 score: \", f1_score(y_test, y_pred, average='weighted'), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[  73    1    0    2]\n",
      " [   0 2462    1   10]\n",
      " [   0    2  386   48]\n",
      " [   1   15   33 2566]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix: \")\n",
    "conf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1,2,3])\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Confusion Matrix: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc2a36bbd10>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "labels = list(label_mapping.keys())\n",
    "print(\"Recall Confusion Matrix: \")\n",
    "recall_conf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1,2,3], normalize='true')\n",
    "sns.heatmap(recall_conf_matrix, annot=True, xticklabels=labels, yticklabels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision Confusion Matrix: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fc294e85950>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Precision Confusion Matrix: \")\n",
    "precision_conf_matrix = confusion_matrix(y_test, y_pred, labels=[0,1,2,3], normalize='pred')\n",
    "sns.heatmap(precision_conf_matrix, annot=True, xticklabels=labels, yticklabels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We notice that despite the significant imbalance between classes (from 100 to 10 000 rows per class), the model achieves an excellent performance overall. The confusion matrix shows that the model results in both high recall and high precision for each class.\n",
    "\n",
    "### It seems that the model is a little less accurate when discriminating between COM and CIV. Indeed, it wrongly classifies 16% of the COM samples as CIV samples. To address this, we could for instance increase the size of the COM dataset to help the model learn more specific representations of COM decisions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is how to use the RNN model to predict the class of a given text sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7fa8ed789e10>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLE: \n",
      "par jugement en date du le tribunal des affaires de sécurité sociale du département du cher a débouté monsieur x de l'opposition qu'il avait formée à l'encontre d'une contrainte qui lui avait été délivrée à la requête de la caisse de mutualité sociale agricole du cher qui par la suite sera désignée comme étant la cmsa pour un montant de 131 134 90 francs le monsieur x a relevé appel de cette décision dont il sollicite de la cour la réformation en ce qu'elle a rejeté son opposition il fait en effet valoir qu'une étude attentive des dispositions législatives et des travaux préparatoires tant de la loi du 8 que de celle du 9 qu'avant l'entrée en vigueur de cette loi les caisses de mutualité sociale agricole devaient respecter les dispositions légales et réglementaires relatives à la constitution des\n",
      "-----------------------------------\n",
      "VECTOR REPRESENTATION OF SAMPLE: \n",
      "[[    7    33     9    43     3     6    36    19   170     1   201    37\n",
      "      3  2640     3  2870    12  1859    20    13     1  2447  1201  2192\n",
      "   1418     8  1149    96  6188   204  1041  2192    62   166     8     2\n",
      "    459     1     2   189     1  2586    37   436     3  2870   204     7\n",
      "      2   947   976  2780  1383   226     2 11254    90   291  2783     1\n",
      "   3881  4327  1232  1581     6    20    13    12  2465   181     1   163\n",
      "     26   147   559  3445     1     2     5     2  2474     9   257  1635\n",
      "     12  1722    44   392   559   497     9  2038  3621  8980 10100 27571\n",
      "     19   136 30345    18    19   808 46526  1086     1     2  1491     3\n",
      "    217   333     1  2626     3   123 46527 13122     9 16827     1   163\n",
      "   1491    55  6693     1  2586    37   436 14150 29659    55   136 15980\n",
      "     18 46528  1775     8     2  4489    19     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0     0     0     0     0\n",
      "      0     0     0     0     0     0     0     0]]\n",
      "-----------------------------------\n",
      "CLASS PREDICTION:  SOC\n",
      "ACTUAL CLASS:  SOC\n"
     ]
    }
   ],
   "source": [
    "k=1 \n",
    "sample = x_test[k].reshape(1,-1)\n",
    "print(\"SAMPLE: \")\n",
    "print(tokens_to_string(sample[0]))\n",
    "print(\"-----------------------------------\")\n",
    "print(\"VECTOR REPRESENTATION OF SAMPLE: \")\n",
    "print(sample)\n",
    "print(\"-----------------------------------\")\n",
    "\n",
    "p = np.argmax(model.predict(sample))\n",
    "y = y_test[k]\n",
    "\n",
    "inverse_label_mapping = {label_mapping[k]:k for k in label_mapping.keys()}\n",
    "print(\"CLASS PREDICTION: \", inverse_label_mapping[p])\n",
    "print(\"ACTUAL CLASS: \", inverse_label_mapping[y])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall, we conclude that the RNN model achieves a very good performance of approximately 97% on the classification of law decisions. Since we only select the first 150 words of each decision, we prove that the beginning of the decision text includes sufficient information to learn discriminative patterns for all 4 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this task, we show how text classification methods can be applied to the legal domain using decision data from social, criminal, commercial and civil justice. However, since the vocabulary is very specific to law decisions, we should not expect the model to generalize well to other areas where the lexical field is drastically different.\n",
    "\n",
    "### Additionally, the text classification was relatively simple in this project because each decision text contains key words which are tightly connected to the classes. For instance, we always have \"Chambre correctionelle\" at the start of a decision related to criminal justice. Similarly, we have \"Chambre sociale\", \"Chambre civile\" and \"Chambre commerciale\" which often appear respectively in decisions for social, civil and commercial justice. Such obvious connections are not always available in law documents and therefore we cannot expect our NLP model to generalize well for a variety of classification tasks in the legal domain.\n",
    "\n",
    "### In general, it can be very complex to automate decisions based on law documents because there are several abstract legal concepts. Also, as time goes by, laws constantly change and legals professionals apply new set of rules. Therefore, the changing nature of law documents also represents a major challenge to NLP in legal contexts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning and Fine-Tuning with Bert model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Lingual Bert Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/amineamor/anaconda3/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:43: UserWarning: You are currently using a nightly version of TensorFlow (2.5.0-dev20210125). \n",
      "TensorFlow Addons offers no support for the nightly versions of TensorFlow. Some things might work, some other might not. \n",
      "If you encounter a bug, do not file an issue on GitHub.\n",
      "  UserWarning,\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_text as text\n",
    "from official.nlp import optimization  # to create AdamW optmizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken:  26.796678000000156  seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "start = time.process_time()\n",
    "\n",
    "tfhub_handle_preprocess = \"/Users/amineamor/Desktop/Bert_Exercise/universal-sentence-encoder-cmlm_multilingual-preprocess_1\"\n",
    "tfhub_handle_encoder = \"/Users/amineamor/Desktop/Bert_Exercise/universal-sentence-encoder-cmlm_multilingual-base-br_1\"\n",
    "# tfhub_handle_encoder= \"/Users/amineamor/Desktop/Bert_Exercise/LaBSE_1\"\n",
    "\n",
    "preprocessor = hub.KerasLayer(tfhub_handle_preprocess)\n",
    "encoder = hub.KerasLayer(tfhub_handle_encoder)\n",
    "\n",
    "\n",
    "print(\"Time taken: \", (time.process_time() - start), \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.85326886 0.13352822 0.18850595]\n",
      " [0.08426897 0.82343245 0.04995594]\n",
      " [0.00991928 0.03902387 0.83902705]]\n"
     ]
    }
   ],
   "source": [
    "def normalization(embeds):\n",
    "    norms = np.linalg.norm(embeds, 2, axis=1, keepdims=True)\n",
    "    return embeds/norms\n",
    "\n",
    "english_sentences = tf.constant([\"dog\", \"Puppies are nice.\", \"I enjoy taking long walks along the beach with my dog.\"])\n",
    "italian_sentences = tf.constant([\"cane\", \"I cuccioli sono carini.\", \"Mi piace fare lunghe passeggiate lungo la spiaggia con il mio cane.\"])\n",
    "japanese_sentences = tf.constant([\"犬\", \"子犬はいいです\", \"私は犬と一緒にビーチを散歩するのが好きです\"])\n",
    "\n",
    "english_embeds = encoder(preprocessor(english_sentences))[\"default\"]\n",
    "japanese_embeds = encoder(preprocessor(japanese_sentences))[\"default\"]\n",
    "italian_embeds = encoder(preprocessor(italian_sentences))[\"default\"]\n",
    "\n",
    "# For semantic similarity tasks, apply l2 normalization to embeddings\n",
    "english_embeds = normalization(english_embeds)\n",
    "japanese_embeds = normalization(japanese_embeds)\n",
    "italian_embeds = normalization(italian_embeds)\n",
    "\n",
    "print (np.matmul(english_embeds, np.transpose(italian_embeds)))\n",
    "\n",
    "# English-Japanese similarity\n",
    "# print (np.matmul(english_embeds, np.transpose(japanese_embeds)))\n",
    "\n",
    "# # Italian-Japanese similarity\n",
    "# print (np.matmul(italian_embeds, np.transpose(japanese_embeds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_embeds = encoder(preprocessor(english_sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence_output': <tf.Tensor: shape=(3, 128, 768), dtype=float32, numpy=\n",
       " array([[[-4.72020954e-01, -3.76940072e-01,  1.48768127e-01, ...,\n",
       "           1.33556873e-03,  3.96905422e-01, -5.27486920e-01],\n",
       "         [-7.20707357e-01, -3.99831772e-01,  6.41182214e-02, ...,\n",
       "          -2.70681679e-01,  6.29583657e-01, -7.20922589e-01],\n",
       "         [-4.72020566e-01, -3.76940072e-01,  1.48768485e-01, ...,\n",
       "           1.33558549e-03,  3.96905631e-01, -5.27486801e-01],\n",
       "         ...,\n",
       "         [-7.06253231e-01,  4.33176756e-05,  7.89681256e-01, ...,\n",
       "          -1.18273884e-01, -1.33401349e-01, -7.10888982e-01],\n",
       "         [-7.45827794e-01,  2.38586426e-01,  6.59201682e-01, ...,\n",
       "           2.01628834e-01,  2.11421698e-01, -8.00969005e-01],\n",
       "         [-7.10339844e-01,  9.82609466e-02,  6.97509527e-01, ...,\n",
       "           9.69182700e-02,  7.70546347e-02, -7.72472739e-01]],\n",
       " \n",
       "        [[-2.38048613e-01, -1.06148887e+00,  6.02737427e-01, ...,\n",
       "          -4.34462190e-01,  5.59268177e-01,  1.09937623e-01],\n",
       "         [-5.76626420e-01, -1.53388393e+00, -8.06403160e-01, ...,\n",
       "          -3.92950237e-01,  7.60681987e-01, -1.19585864e-01],\n",
       "         [ 4.01714504e-01, -1.34745669e+00,  4.49213594e-01, ...,\n",
       "          -3.81800205e-01,  3.23860347e-01, -1.07810050e-02],\n",
       "         ...,\n",
       "         [-1.96088761e-01, -8.81072521e-01,  1.16685534e+00, ...,\n",
       "          -3.37705791e-01,  3.68476212e-02,  2.78237611e-01],\n",
       "         [-1.53657556e-01, -9.20060098e-01,  1.09766018e+00, ...,\n",
       "          -2.95424700e-01,  6.32231236e-02,  2.84388065e-01],\n",
       "         [-1.54660538e-01, -9.06039119e-01,  1.04034042e+00, ...,\n",
       "          -2.14752153e-01,  7.21861273e-02,  2.25821987e-01]],\n",
       " \n",
       "        [[ 1.43848026e+00,  1.21513247e-01, -4.21833485e-01, ...,\n",
       "          -5.25785148e-01, -2.53165483e-01, -1.07410836e+00],\n",
       "         [ 9.14351940e-01,  2.94097885e-02, -1.24981320e+00, ...,\n",
       "          -7.99026012e-01, -1.62935257e+00, -1.09478271e+00],\n",
       "         [ 1.97420037e+00, -1.75563931e-01, -9.33554471e-01, ...,\n",
       "          -6.76752388e-01, -1.03490460e+00, -7.57972181e-01],\n",
       "         ...,\n",
       "         [ 8.96305680e-01,  4.92174208e-01,  5.07253170e-01, ...,\n",
       "          -2.79972330e-02, -7.37185478e-01, -1.08744252e+00],\n",
       "         [ 9.05147135e-01,  6.40204370e-01,  2.84897625e-01, ...,\n",
       "           1.33183077e-01, -8.38077784e-01, -1.13503242e+00],\n",
       "         [ 9.13187325e-01,  6.76577687e-01,  2.42049038e-01, ...,\n",
       "           1.92038730e-01, -8.53646398e-01, -1.14171708e+00]]],\n",
       "       dtype=float32)>,\n",
       " 'default': <tf.Tensor: shape=(3, 768), dtype=float32, numpy=\n",
       " array([[-0.5549163 , -0.38457063,  0.12055161, ..., -0.08933684,\n",
       "          0.4744649 , -0.59196544],\n",
       "        [-0.05301094, -1.4580522 ,  0.34361938, ..., -0.57730097,\n",
       "          0.48154485,  0.32916105],\n",
       "        [ 1.2552203 ,  0.28868625, -0.7675113 , ..., -0.37791356,\n",
       "         -0.3515516 , -1.0740645 ]], dtype=float32)>,\n",
       " 'pooled_output': <tf.Tensor: shape=(3, 768), dtype=float32, numpy=\n",
       " array([[-0.5549163 , -0.38457063,  0.12055161, ..., -0.08933684,\n",
       "          0.4744649 , -0.59196544],\n",
       "        [-0.05301094, -1.4580522 ,  0.34361938, ..., -0.57730097,\n",
       "          0.48154485,  0.32916105],\n",
       "        [ 1.2552203 ,  0.28868625, -0.7675113 , ..., -0.37791356,\n",
       "         -0.3515516 , -1.0740645 ]], dtype=float32)>}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(data_text, data_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 1.],\n",
       "       [0., 1., 0., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "y_train_enc = enc.fit_transform(np.array(y_train).reshape(-1,1)).toarray()\n",
    "y_test_enc = enc.fit_transform(np.array(y_test).reshape(-1,1)).toarray()\n",
    "\n",
    "y_test_enc[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'text_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-f1b7d1ba1eff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mclassifier_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_classifier_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mbert_raw_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_raw_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'text_test' is not defined"
     ]
    }
   ],
   "source": [
    "def build_classifier_model():\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='text')\n",
    "    preprocessing_layer = hub.KerasLayer(tfhub_handle_preprocess, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(tfhub_handle_encoder, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    net = tf.keras.layers.Dropout(0.1)(net)\n",
    "    net = tf.keras.layers.Dense(4, activation='softmax', name='classifier')(net)\n",
    "    return tf.keras.Model(text_input, net)\n",
    "\n",
    "\n",
    "classifier_model = build_classifier_model()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.40353522 0.3925422  0.18949722 0.01442525]], shape=(1, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "text_test = ['this is such an amazing movie!']\n",
    "bert_raw_result = classifier_model(tf.constant(text_test))\n",
    "print((bert_raw_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None,)]            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "preprocessing (KerasLayer)      {'input_word_ids': ( 0           text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "BERT_encoder (KerasLayer)       {'sequence_output':  470926849   preprocessing[0][0]              \n",
      "                                                                 preprocessing[0][1]              \n",
      "                                                                 preprocessing[0][2]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 768)          0           BERT_encoder[0][1]               \n",
      "__________________________________________________________________________________________________\n",
      "classifier (Dense)              (None, 4)            3076        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 470,929,925\n",
      "Trainable params: 470,929,924\n",
      "Non-trainable params: 1\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classifier_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "metrics = tf.metrics.Accuracy()\n",
    "epochs = 5\n",
    "\n",
    "\n",
    "classifier_model.compile(loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  2/315 [..............................] - ETA: 11:51:57 - loss: 2.2113 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-03d7af2edd60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_enc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1132\u001b[0m                 _r=1):\n\u001b[1;32m   1133\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2992\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2993\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2994\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2996\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1937\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1938\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1939\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1940\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1941\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    567\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 569\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    570\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = classifier_model.fit(x_train, y_train_enc, validation_split=0.10, epochs=epochs, batch_size=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
